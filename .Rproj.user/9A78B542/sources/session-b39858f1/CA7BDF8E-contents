# Analyse des co-occurrences dans Maria Chapdelaine

setwd("~/Downloads")


if(!"udpipe" %in% rownames(installed.packages())){install.packages("udpipe")}
if(!"data.table" %in% rownames(installed.packages())){install.packages("data.table")}
if(!"stringr" %in% rownames(installed.packages())){install.packages("stringr")}
if(!"textrank" %in% rownames(installed.packages())){install.packages("textrank")}

# Activer les extensions
libs <- c( "stringr", "tidytext", "lsa", "udpipe", "data.table", "textrank", "gutenbergr")
lapply(libs, require, character.only = TRUE)
rm(list = ls())


# Création du chemin du modèle d'annotation
model_dir <- paste0(getwd(), '/modele_udpipe')

# Télécharger le modèle d'annotation
udtarget <- udpipe_download_model(language = "french-gsd", model_dir = model_dir)

# Importer dans l'environnement de travail le modèle d'annotation téléchargé
udmodel <- udpipe_load_model(file = udtarget$file_model)

# Importation du texte de Maria Chapdelaine avec son identifiant unique
maria <- gutenberg_download(13525, mirror = "http://mirror.csclub.uwaterloo.ca/gutenberg/")

# Transformation de l'encodage des chaînes de caractères du vecteur text
maria$text <- iconv(maria$text, from = "latin1", "utf8")

# Élimination des lignes blanches
maria <- maria[maria$text != "", ]

# Inspection des 10 premières lignes
maria[1:10, ]

# Élimination du péritexte
maria <- maria[grep("CHAPITRE I\\b", maria$text):nrow(maria), ]

# On s'assure que la fin du roman coïncide bien avec la dernière ligne du document
maria[(nrow(maria)-10):nrow(maria), ]

# Assemblage du texte en un vecteur de longueur 1
maria_v <- paste(maria$text, collapse = " ")


x <- udpipe_annotate(udmodel,
                                    maria_v,
                                    doc_id = "maria_chapdelaine",
                                    parallel.cores = 10
) %>% as.data.table(.) %>%
  subset(., !is.na(upos)) # Élimination des éléments que le modèle n'a pu annoter


stats <- subset(x, upos %in% "NOUN")
stats <- txt_freq(x = stats$lemma)

library(lattice)
stats$key <- factor(stats$key, levels = rev(stats$key))
barchart(key ~ freq, data = head(stats, 30), col = "cadetblue", main = "Most occurring nouns", xlab = "Freq")


## Collocation (words following one another)
stats <- keywords_collocation(x = x, 
                              term = "token", group = c("doc_id", "paragraph_id", "sentence_id"),
                              ngram_max = 4)
## Co-occurrences: How frequent do words occur in the same sentence, in this case only nouns or adjectives
stats <- cooccurrence(x = subset(x, upos %in% c("NOUN", "ADJ")), 
                      term = "lemma", group = c("doc_id", "paragraph_id", "sentence_id"))

## Co-occurrences: How frequent do words follow one another
stats <- cooccurrence(x = x$lemma, 
                      relevant = x$upos %in% c("NOUN", "ADJ"))

## Co-occurrences: How frequent do words follow one another even if we would skip 2 words in between
stats <- cooccurrence(x = x$lemma, 
                      relevant = x$upos %in% c("NOUN", "ADJ"), skipgram = 2)
head(stats)

library(igraph)
library(ggraph)
library(ggplot2)
wordnetwork <- head(stats, 30)
wordnetwork <- graph_from_data_frame(wordnetwork)
ggraph(wordnetwork, layout = "fr") +
  geom_edge_link(aes(width = cooc, edge_alpha = cooc), edge_colour = "pink") +
  geom_node_text(aes(label = name), col = "darkgreen", size = 4) +
  theme_graph(base_family = "Arial Narrow") +
  theme(legend.position = "none") +
  labs(title = "Cooccurrences within 3 words distance", subtitle = "Nouns & Adjective")





stats <- textrank_keywords(x$lemma, 
                           relevant = x$upos %in% c("NOUN", "ADJ"), 
                           ngram_max = 8, sep = " ")
stats <- subset(stats$keywords, ngram > 1 & freq >= 3)
library(wordcloud)
wordcloud(words = stats$keyword, freq = stats$freq)


stats <- keywords_rake(x = x, 
                       term = "token", group = c("doc_id", "paragraph_id", "sentence_id"),
                       relevant = x$upos %in% c("NOUN", "ADJ"),
                       ngram_max = 4)
head(subset(stats, freq > 3))





## Simple noun phrases (a adjective+noun, pre/postposition, optional determiner and another adjective+noun)
x$phrase_tag <- as_phrasemachine(x$upos, type = "upos")
stats <- keywords_phrases(x = x$phrase_tag, term = x$token, 
                          pattern = "(A|N)+N(P+D*(A|N)*N)*", 
                          is_regex = TRUE, ngram_max = 4, detailed = FALSE)
head(subset(stats, ngram > 2))







stats <- merge(x, x, 
               by.x = c("doc_id", "paragraph_id", "sentence_id", "head_token_id"),
               by.y = c("doc_id", "paragraph_id", "sentence_id", "token_id"),
               all.x = TRUE, all.y = FALSE, 
               suffixes = c("", "_parent"), sort = FALSE)
stats <- subset(stats, dep_rel %in% "nsubj" & upos %in% c("NOUN") & upos_parent %in% c("ADJ"))
stats$term <- paste(stats$lemma_parent, stats$lemma, sep = " ")
stats <- txt_freq(stats$term)
library(wordcloud)
wordcloud(words = stats$key, freq = stats$freq, min.freq = 3, max.words = 100,
          random.order = FALSE, colors = c("#1B9E77", "#D95F02", "#7570B3", "#E7298A", "#66A61E", "#E6AB02"))



